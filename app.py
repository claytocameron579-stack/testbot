# app.py
from flask import Flask, request
import requests
import os
import re
from urllib.parse import quote_plus, urlparse
from bs4 import BeautifulSoup
import google.generativeai as genai

app = Flask(__name__)

# ----------------------------------------------------
# Environment
# ----------------------------------------------------
BOT_TOKEN = os.environ.get("BOT_TOKEN")
TELEGRAM_API = f"https://api.telegram.org/bot{BOT_TOKEN}"

GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
GEMINI_MODEL = os.environ.get("GEMINI_MODEL", "gemini-2.5-flash")

# ูุฑุฌุน ุณุงุช
SITE_BASE_URL = os.environ.get("SITE_BASE_URL", "https://irancoral.ir")

# Gemini init
genai.configure(api_key=GEMINI_API_KEY)

# ----------------------------------------------------
# Utilities
# ----------------------------------------------------
UA_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/124.0 Safari/537.36"
    )
}

def send_telegram(chat_id, text):
    try:
        requests.post(
            f"{TELEGRAM_API}/sendMessage",
            json={"chat_id": chat_id, "text": text},
            timeout=8,
        )
    except Exception as e:
        print("Telegram send error:", e)

def is_persian_text(text: str) -> bool:
    # ุงฺฏุฑ ุญุฏุงูู ฺฉ ฺฉุงุฑุงฺฉุชุฑ ูุงุฑุณ/ุนุฑุจ ูุฌูุฏ ุฏุงุดุชู ุจุงุดุฏุ ูุงุฑุณ ุฏุฑ ูุธุฑ ุจฺฏุฑ
    return any('\u0600' <= ch <= '\u06FF' for ch in text)

def is_english_only(text: str) -> bool:
    # ุงฺฏุฑ ูฺ ฺฉุงุฑุงฺฉุชุฑ ูุงุฑุณ ูุจุงุดุฏ ู ุนูุฏุชุงู ASCII ุจุงุดุฏุ ุงูฺฏูุณู ฺฉุงูู
    if is_persian_text(text):
        return False
    try:
        text.encode("ascii")
        return True
    except UnicodeEncodeError:
        return False

def http_get(url: str, timeout=12):
    return requests.get(url, headers=UA_HEADERS, timeout=timeout)

def normalize_url(u: str) -> str:
    # ููุท ููฺฉโูุง ุฏุงุฎู irancoral.ir ุฑุง ูุจูู ฺฉู
    try:
        p = urlparse(u)
        if not p.scheme:
            u = SITE_BASE_URL.rstrip('/') + '/' + u.lstrip('/')
        if "irancoral.ir" in urlparse(u).netloc:
            return u
    except Exception:
        pass
    return ""

# ----------------------------------------------------
# IranCoral Crawling (ุณุจฺฉ ู ุณุฑุน)
# ----------------------------------------------------
def extract_product_info(url: str) -> str:
    """
    ุชูุงุด ุจุฑุง ุจุฑููโฺฉุดุฏู ุฏุงุฏูโูุง ูุญุตูู ููฺฉุงูุฑุณ ุงุฒ irancoral.ir
    """
    try:
        url = normalize_url(url)
        if not url:
            return ""
        r = http_get(url)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")

        title = (
            (soup.select_one("h1.product_title") or soup.select_one("h1.entry-title"))
            or soup.find("h1")
        )
        title = title.get_text(strip=True) if title else ""

        # ููุช
        price_el = soup.select_one(".woocommerce-Price-amount")
        if not price_el:
            price_el = soup.select_one(".price")
        price = price_el.get_text(strip=True) if price_el else ""

        # ูุถุนุช ููุฌูุฏ
        stock_el = soup.select_one(".stock")
        stock = stock_el.get_text(strip=True) if stock_el else ""

        # ุชูุถุญ ฺฉูุชุงู ูุญุตูู
        short_desc_el = soup.select_one(".woocommerce-product-details__short-description")
        if not short_desc_el:
            # fallback: ุจุฎุด ุชูุถุญุงุช ุชุจ ุงุตู
            short_desc_el = soup.select_one("#tab-description") or soup.select_one(".entry-content")
        short_desc = short_desc_el.get_text(" ", strip=True)[:800] if short_desc_el else ""

        # ุชุฌูุน
        chunks = []
        if title: chunks.append(f"ูุงู ูุญุตูู: {title}")
        if price: chunks.append(f"ููุช: {price}")
        if stock: chunks.append(f"ููุฌูุฏ: {stock}")
        if short_desc: chunks.append(f"ุชูุถุญ: {short_desc}")
        chunks.append(f"ููฺฉ: {url}")

        return "\n".join(chunks).strip()
    except Exception as e:
        print("extract_product_info error:", e)
        return ""

def extract_article_info(url: str) -> str:
    """
    ุฏุฑ ุตูุฑุช ููุงูู/ุจุฑฺฏู: ูุชู ุงุตู ุฑุง ุฎูุงุตู ุงุณุชุฎุฑุงุฌ ฺฉู
    """
    try:
        url = normalize_url(url)
        if not url:
            return ""
        r = http_get(url)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")
        content = soup.select_one(".entry-content") or soup.find("article") or soup.body
        text = content.get_text(" ", strip=True) if content else ""
        text = re.sub(r"\s+", " ", text).strip()
        if not text:
            return ""
        return f"ููุงูู/ุตูุญู: {url}\nูุชู: {text[:2000]}"
    except Exception as e:
        print("extract_article_info error:", e)
        return ""

def site_search_snippets(query: str, limit_pages: int = 5):
    """
    ุฌุณุชุฌู ุณุงุฏู ุฏุฑ ุณุงุช ุจุง ูพุงุฑุงูุชุฑ ?s= (ูุฑุฏูพุฑุณ) ู ุงุณุชุฎุฑุงุฌ ฺูุฏ ูุชุฌู ุงูู
    ุณูพุณ ูุฑ ููฺฉ ุฑุง ุจุงุฒ ฺฉุฑุฏู ู ุฎูุงุตูโุง ฺฉูุชุงู ูโุณุงุฒุฏ.
    """
    try:
        search_url = f"{SITE_BASE_URL.rstrip('/')}/?s={quote_plus(query)}"
        r = http_get(search_url)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")

        links = []
        # ูุชุงุฌ ูุญุตูู ููฺฉุงูุฑุณ
        for a in soup.select("a.woocommerce-LoopProduct-link"):
            href = a.get("href")
            if href: links.append(href)
        # ูุชุงุฌ ููุงูู/ูพุณุช
        for h2 in soup.select("h2.entry-title a"):
            href = h2.get("href")
            if href: links.append(href)

        # ฺฉุชุง ู ูุญุฏูุฏ
        seen = set()
        uniq = []
        for u in links:
            u = normalize_url(u)
            if u and u not in seen:
                uniq.append(u)
                seen.add(u)
            if len(uniq) >= limit_pages:
                break

        snippets = []
        for u in uniq:
            if "/product/" in u:
                info = extract_product_info(u)
            else:
                info = extract_article_info(u)
            if info:
                snippets.append(info)
        return snippets
    except Exception as e:
        print("site_search_snippets error:", e)
        return []

def extract_irancoral_context(user_text: str, max_total_chars: int = 3500) -> str:
    """
    - ุงฺฏุฑ ฺฉุงุฑุจุฑ ููฺฉ irancoral ุฏุงุฏ: ููุงูโูุง ุฑุง ุงุณุชุฎุฑุงุฌ ฺฉู
    - ุฏุฑ ุบุฑ ุงู ุตูุฑุช: ุจุง ?s= ุฌุณุชุฌู ฺฉู ู ฺูุฏ ูุชุฌู ุฎูุงุตู ุจุฑฺฏุฑุฏุงู
    """
    # ููฺฉโูุง ุงุฑุงูโฺฉูุฑุงู ุฏุงุฎู ูพุงู
    urls = re.findall(r"https?://[^\s]+", user_text)
    urls = [u for u in urls if "irancoral.ir" in u]

    ctx_parts = []
    total = 0

    if urls:
        for u in urls:
            block = extract_product_info(u) if "/product/" in u else extract_article_info(u)
            if block:
                ctx_parts.append(block)
                total += len(block)
                if total >= max_total_chars:
                    break
    else:
        # ุฌุณุชุฌู ุขุฒุงุฏ ุฏุฑ ุณุงุช
        snips = site_search_snippets(user_text, limit_pages=4)
        for s in snips:
            ctx_parts.append(s)
            total += len(s)
            if total >= max_total_chars:
                break

    return "\n\n---\n\n".join(ctx_parts)

# ----------------------------------------------------
# Gemini wrapper (ููุท ุจุฑ ุงุณุงุณ ฺฉุงูุชฺฉุณุช ุงุฑุงูโฺฉูุฑุงู)
# ----------------------------------------------------
def get_ai_reply_from_irancoral(user_message: str) -> str:
    # ุณุงุณุช ุฒุจุงู:
    # - ุงฺฏุฑ ฺฉุงุฑุจุฑ ฺฉุงููุงู ุบุฑ ูุงุฑุณ ููุดุช => ุงุฌุงุฒู ุงูฺฏูุณ
    # - ุฏุฑ ุบุฑ ุงู ุตูุฑุช => ูุงุฑุณ ุงุฌุจุงุฑ
    allow_english = is_english_only(user_message)
    lang_instruction = (
        "Always answer in English." if allow_english
        else "ููุท ู ููุท ุจู ุฒุจุงู ูุงุฑุณ ูพุงุณุฎ ุจุฏู."
    )

    # ฺฉุงูุชฺฉุณุช ุงุฒ ุงุฑุงูโฺฉูุฑุงู
    context = extract_irancoral_context(user_message)

    # ุงฺฏุฑ ูฺ ฺฉุงูุชฺฉุณุช ูุชููุณุชู ุจฺฏุฑูุ ูุฏู ุฑุง ูุฌุจูุฑ ฺฉูู ุจู ุตุฑุงุญุช ุจฺฏูุฏ ุจู ููุจุน ุงุฑุงูโฺฉูุฑุงู ุฏุณุชุฑุณ ูุฏุงุฑุฏ
    if not context:
        context = (
            "ููุงุจุน ุงุฑุงูโฺฉูุฑุงู ุงูุช ูุดุฏ. ุงฺฏุฑ ูพุงุณุฎ ูุงุฒ ุจู ููุจุน ุฏุงุฑุฏุ "
            "ุตุฑุงุญุชุงู ุจฺฏู ฺฉู ูุชุฌูโุง ุงุฒ irancoral.ir ูพุฏุง ูุดุฏ ู ุณุคุงู ุชฺฉูู ุจูพุฑุณ."
        )

    system_instruction = (
        f"{lang_instruction}\n"
        "ุชู ฺฉ ฺฉุงุฑุดูุงุณ ุขฺฉูุงุฑูู ู ูุงูโูุง ุฒูุช ู ูุฑูุดฺฏุงู ุงุฑุงูโฺฉูุฑุงู ูุณุช. "
        "ูุงููู ุทูุง: ููุท ู ููุท ุจุฑ ุงุณุงุณ ุงุทูุงุนุงุช ฺฉู ุงุฒ ุณุงุช irancoral.ir ุฏุฑ ยซุจุฎุด ููุงุจุนยป ุงุฑุณุงู ูโุดูุฏ ูพุงุณุฎ ุจุฏู. "
        "ุงฺฏุฑ ููุงุจุน ุจุฑุง ูพุงุณุฎ ฺฉุงู ูุณุชุ ุฎู ฺฉูุชุงู ุจฺฏู ฺฉู ููุงุจุน ฺฉุงู ุงุฒ ุงุฑุงูโฺฉูุฑุงู ูพุฏุง ูุดุฏ ู ุจูพุฑุณ ฺู ุฌุฒุฆุงุช ูโุฎูุงูุฏ. "
        "ุงฺฏุฑ ูุญุตูู ููุงุณุจ ุฏุฑ ููุงุจุน ุจูุฏุ ููุงู ุฑุง ุจุง ููฺฉ ุงุฑุงูโฺฉูุฑุงู ูพุดููุงุฏ ุจุฏู. "
        "ุงุฒ ุฎูุฏุช ฺุฒ ุงุถุงูู ูฺฉูุ ู ุงุฒ ููุงุจุน ุบุฑ ุงุฑุงูโฺฉูุฑุงู ุงุณุชูุงุฏู ูฺฉู."
    )

    prompt = (
        f"{system_instruction}\n\n"
        f"ุจุฎุด ููุงุจุน (ุงุฒ irancoral.ir):\n{context}\n\n"
        f"ูพุฑุณุด ฺฉุงุฑุจุฑ:\n{user_message}"
    )

    try:
        model = genai.GenerativeModel(GEMINI_MODEL)
        resp = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.2,
                max_output_tokens=450,
            ),
        )
        text = (resp.text or "").strip() if hasattr(resp, "text") else ""
        # ูพุงฺฉุณุงุฒ ุฎู ุณุจฺฉ (ุงฺฏุฑ ุงุญุงูุงู ูุฑูุช ุนุฌุจ ุขูุฏ)
        text = re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL|re.IGNORECASE).strip()
        if not text:
            return "โ๏ธ ูพุงุณุฎ ุชููุฏ ูุดุฏ. ูุทูุงู ุณุคุงู ุฑุง ุฏููโุชุฑ ุจูุฑูุงุฏ."
        return text
    except Exception as e:
        print("Gemini error:", e)
        return "โ ุฎุทุง ุฏุฑ ุงุชุตุงู ุจู ูุฏู ููุด ูุตููุนุ ฺฉู ุจุนุฏ ุฏูุจุงุฑู ุชูุงุด ฺฉูุฏ."

# ----------------------------------------------------
# Flask routes
# ----------------------------------------------------
@app.route("/")
def home():
    return "๐ค IranCoral AI assistant is running."

@app.route("/webhook", methods=["POST"])
def webhook():
    data = request.get_json() or {}
    msg = data.get("message", {})
    chat_id = msg.get("chat", {}).get("id")
    text = (msg.get("text") or "").strip()

    if not chat_id or not text:
        return "ok"

    reply = get_ai_reply_from_irancoral(text)
    send_telegram(chat_id, reply)
    return "ok"

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 5000)))
